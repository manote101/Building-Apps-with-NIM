{"cells":[{"cell_type":"markdown","id":"22a65794","metadata":{"id":"22a65794"},"source":["# üìù RAGPipeline: ChatNVIDIA + NVIDIAEmbeddings + ChromaDB\n","This notebook defines a reusable Python class for building RAG applications."]},{"cell_type":"code","execution_count":null,"id":"3f0ef102","metadata":{"id":"3f0ef102"},"outputs":[],"source":["# Install required libraries (if not already installed)\n","!pip install -q langchain-community langchain-chroma langchain-nvidia-ai-endpoints"]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","os.environ['NVIDIA_API_KEY'] = userdata.get('NVIDIA_API_KEY')"],"metadata":{"id":"yT7ml_ny8K6P"},"id":"yT7ml_ny8K6P","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SKIP THIS CELL, in case you access local NIM on your own server\n","import os\n","\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv()) # read local .env file\n","apikey = os.getenv('NVIDIA_API_KEY', \"no-pass\")"],"metadata":{"id":"s4rMtz888Na-"},"id":"s4rMtz888Na-","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"6aee6b9d","metadata":{"id":"6aee6b9d"},"source":["## üìÇ Setup Imports and Define RAGPipeline Class"]},{"cell_type":"code","execution_count":null,"id":"f36fed68","metadata":{"id":"f36fed68"},"outputs":[],"source":["import hashlib\n","import os\n","\n","from langchain_community.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","# from langchain_community.vectorstores import Chroma\n","from langchain_chroma import Chroma\n","from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n","from langchain_nvidia_ai_endpoints import ChatNVIDIA\n","from langchain.chains import RetrievalQA\n","\n","# --- Configuration ---\n","LLM_ENDPOINT = \"https://integrate.api.nvidia.com/v1\"\n","LLM_MODEL = \"meta/llama-3.2-3b-instruct\"\n","\n","EMBEDDING_ENDPOINT = \"https://integrate.api.nvidia.com/v1\"\n","EMBEDDING_MODEL = \"nvidia/llama-3.2-nv-embedqa-1b-v2\"\n","\n","class RAGPipeline:\n","    def __init__(self, document_path, chroma_dir, hash_file, embedding_model=EMBEDDING_MODEL, chat_model=LLM_MODEL, chunk_size=500, chunk_overlap=50):\n","        self.document_path = document_path\n","        self.chroma_dir = chroma_dir\n","        self.hash_file = hash_file\n","        self.embedding_model = embedding_model\n","        self.chat_model = chat_model\n","        self.chunk_size = chunk_size\n","        self.chunk_overlap = chunk_overlap\n","        self.vector_db = None\n","        self.qa_chain = None\n","\n","    def compute_md5(self):\n","        hash_md5 = hashlib.md5()\n","        with open(self.document_path, \"rb\") as f:\n","            for chunk in iter(lambda: f.read(4096), b\"\"):\n","                hash_md5.update(chunk)\n","        return hash_md5.hexdigest()\n","\n","    def document_changed(self):\n","        current_hash = self.compute_md5()\n","        if os.path.exists(self.hash_file):\n","            with open(self.hash_file, \"r\") as f:\n","                saved_hash = f.read().strip()\n","            if current_hash == saved_hash:\n","                print(\"‚úÖ Document has not changed. Using existing vector store.\")\n","                return False\n","        with open(self.hash_file, \"w\") as f:\n","            f.write(current_hash)\n","        print(\"üîÑ Document changed or first run. Rebuilding vector store...\")\n","        return True\n","\n","    def build_vector_store(self):\n","        if self.document_changed():\n","            loader = TextLoader(self.document_path)\n","            documents = loader.load()\n","            text_splitter = RecursiveCharacterTextSplitter(\n","                chunk_size=self.chunk_size,\n","                chunk_overlap=self.chunk_overlap\n","            )\n","            docs = text_splitter.split_documents(documents)\n","            embedding_function = NVIDIAEmbeddings(base_url=EMBEDDING_ENDPOINT, model=self.embedding_model)\n","            self.vector_db = Chroma.from_documents(\n","                documents=docs,\n","                embedding=embedding_function,\n","                persist_directory=self.chroma_dir\n","            )\n","        else:\n","            embedding_function = NVIDIAEmbeddings(base_url=EMBEDDING_ENDPOINT, model=self.embedding_model)\n","            self.vector_db = Chroma(\n","                persist_directory=self.chroma_dir,\n","                embedding_function=embedding_function\n","            )\n","\n","    def setup_qa_chain(self):\n","        if self.vector_db is None:\n","            self.build_vector_store()\n","        retriever = self.vector_db.as_retriever(search_kwargs={\"k\": 3})\n","\n","        llm = ChatNVIDIA(base_url=LLM_ENDPOINT, model=self.chat_model, temperature=0)\n","        self.qa_chain = RetrievalQA.from_chain_type(\n","            llm=llm,\n","            retriever=retriever,\n","            return_source_documents=True\n","        )\n","\n","    def ask(self, query):\n","        if self.qa_chain is None:\n","            self.setup_qa_chain()\n","        result = self.qa_chain(query)\n","        print(\"\\n‚úÖ Answer:\", result[\"result\"])\n","        print(\"\\nüìÑ Sources:\")\n","        for doc in result[\"source_documents\"]:\n","            print(\"-\", doc.metadata.get(\"source\", \"Unknown\"))\n","        return result"]},{"cell_type":"markdown","id":"76674c98","metadata":{"id":"76674c98"},"source":["## üöÄ Initialize and Use RAGPipeline"]},{"cell_type":"code","source":["# download sample data\n","!git clone https://github.com/manote101/Building-Apps-with-NIM.git"],"metadata":{"id":"C9_NLSoQDUMs"},"id":"C9_NLSoQDUMs","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"730ce64b","metadata":{"id":"730ce64b"},"outputs":[],"source":["# Initialize pipeline\n","pipeline = RAGPipeline(\n","    document_path=\"Building-Apps-with-NIM/data/doc1.txt\",\n","    chroma_dir=\"./chroma_db\",\n","    hash_file=\"Building-Apps-with-NIM/data/doc_hash.txt\"\n",")\n","\n","# Ask a question\n","pipeline.ask(\"Are there any service providers/ISVs who already implemented Nemo Microservices?\")"]},{"cell_type":"code","execution_count":null,"id":"e96bcf10-3f65-46de-a514-afb91f395156","metadata":{"id":"e96bcf10-3f65-46de-a514-afb91f395156"},"outputs":[],"source":["pipeline.ask(\"‡∏°‡∏µ‡πÉ‡∏Ñ‡∏£‡πÉ‡∏ä‡πâ Nemo microservices ‡∏ö‡πâ‡∏≤‡∏á\")"]},{"cell_type":"code","execution_count":null,"id":"67d391b4-b1ef-45bb-8100-1b6ea86f8a7b","metadata":{"id":"67d391b4-b1ef-45bb-8100-1b6ea86f8a7b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"204ff76b-0f74-40f5-b9bf-bb4daca31fba","metadata":{"id":"204ff76b-0f74-40f5-b9bf-bb4daca31fba"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}