{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0pd3FYpNqT9slbw6DUY+G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Fundamentals of Prompt Engineering\n","\n","In this chapter, you'll learn:\n","- What makes a good prompt\n","- How to use roles (`system`, `user`, `assistant`)\n","- Control generation with `temperature` and `max_tokens`\n","- Few-shot prompting techniques"],"metadata":{"id":"z4KcykpDt1Ky"}},{"cell_type":"markdown","source":["### üîß Setup: Install Required Library"],"metadata":{"id":"xzMSHortQvgB"}},{"cell_type":"code","source":["# !pip install -q python-dotenv"],"metadata":{"id":"da82wyjGvRNa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### üß™ Step 1: Connect to Your LLM Endpoint\n"],"metadata":{"id":"hatY37tsRQkN"}},{"cell_type":"code","source":["from openai import OpenAI\n","import os\n","\n","from google.colab import userdata\n","os.environ['NVIDIA_API_KEY'] = userdata.get('NVIDIA_API_KEY')\n","apikey = os.getenv('NVIDIA_API_KEY')\n","\n","# from dotenv import load_dotenv, find_dotenv\n","# load_dotenv(find_dotenv())  # Load .env file\n","# apikey = os.getenv('NVIDIA_API_KEY')\n","\n","\n","client = OpenAI(\n","    base_url=\"https://integrate.api.nvidia.com/v1\",\n","    api_key=apikey\n",")"],"metadata":{"id":"z3-Cd4uJRgO-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### üí¨ Example: Temperature and Max Tokens"],"metadata":{"id":"Ld0xz8GnRBEG"}},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Explain why the sky is blue.\"}\n","]\n","\n","response = client.chat.completions.create(\n","    model=\"meta/llama-3.2-3b-instruct\",\n","    messages=messages,\n","    temperature=0.5,\n","    max_tokens=100\n",")\n","\n","print(response.choices[0].message.content)"],"metadata":{"id":"LKU7mvqURGYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Write blog about my trip to Yosemiti National Park.\"}\n","]\n","\n","response = client.chat.completions.create(\n","    model=\"meta/llama-3.2-3b-instruct\",\n","    messages=messages,\n","    temperature=0.5,\n","    max_tokens=100\n",")\n","\n","print(response.choices[0].message.content)"],"metadata":{"id":"t1fcyuAphQ49"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### üí° Few-Shot Prompting Example"],"metadata":{"id":"m2S2B1izdTD2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"J32bZewXt0Hq"},"outputs":[],"source":["messages = [\n","    {\"role\": \"system\", \"content\": \"You are a translation assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Apple ‚Üí ‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡∏•\"},\n","    {\"role\": \"assistant\", \"content\": \"Dog ‚Üí ‡∏´‡∏°‡∏≤\"},\n","    {\"role\": \"user\", \"content\": \"Car\"}\n","]\n","\n","response = client.chat.completions.create(\n","    model=\"meta/llama-3.2-3b-instruct\",\n","    messages=messages,\n","    temperature=0.2\n",")\n","\n","print(response.choices[0].message.content)\n"]},{"cell_type":"markdown","source":["### üìù Exercise\n","Try writing a prompt that asks the model to generate a poem about rain in the style of Shakespeare"],"metadata":{"id":"EeN-1zSNTbP5"}},{"cell_type":"code","source":[],"metadata":{"id":"4oXF6qSkdqIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Be3jcIatT1Tr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XkTWUCDIcQtF"},"execution_count":null,"outputs":[]}]}