{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQlNRwIvinwrOlWanxlgxR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### First Program to connect NVIDIA NIM via OpenAI API Calls\n","\n","In this chapter, you'll learn:\n","- What a Large Language Model (LLM) is\n","- How to connect to an OpenAI-compatible API endpoint\n","- How to make your first request using Python\n","- The basics of interacting with `meta/llama-3.2-3b-instruct`"],"metadata":{"id":"z4KcykpDt1Ky"}},{"cell_type":"markdown","source":["### üîß Setup: Install Required Library"],"metadata":{"id":"xzMSHortQvgB"}},{"cell_type":"code","source":["# !pip install -q python-dotenv"],"metadata":{"id":"da82wyjGvRNa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### üß™ Step 1: Connect to Your LLM Endpoint\n","* Set 'NVIDIA_API_KEY' Shell variable. Choices can be:\n","   * Read from Colab Repo\n","   * Read from .env file\n","   * Set in your Shell configuration file, i.e. .bashrc or command line"],"metadata":{"id":"hatY37tsRQkN"}},{"cell_type":"code","source":["from openai import OpenAI\n","import os\n","\n","from google.colab import userdata\n","os.environ['NVIDIA_API_KEY'] = userdata.get('NVIDIA_API_KEY')\n","apikey = os.getenv('NVIDIA_API_KEY')\n","\n","# from dotenv import load_dotenv, find_dotenv\n","# load_dotenv(find_dotenv())  # Load .env file\n","# apikey = os.getenv('NVIDIA_API_KEY')\n","\n","\n","client = OpenAI(\n","    base_url=\"https://integrate.api.nvidia.com/v1\",\n","    api_key=apikey\n",")"],"metadata":{"id":"z3-Cd4uJRgO-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### üí¨ Step 2: Make Your First API Call"],"metadata":{"id":"Ld0xz8GnRBEG"}},{"cell_type":"code","source":["# Send a simple message to the LLM\n","response = client.chat.completions.create(\n","    model=\"meta/llama-3.2-3b-instruct\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": \"Tell me a short joke.\"}\n","    ]\n",")\n","\n","# Print the response\n","print(response.choices[0].message.content)"],"metadata":{"id":"LKU7mvqURGYk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Alternative #1: Use OpenAI standart library"],"metadata":{"id":"m2S2B1izdTD2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"J32bZewXt0Hq"},"outputs":[],"source":["completion = client.chat.completions.create(\n","    model=\"meta/llama-3.2-3b-instruct\",\n","    messages=[{\"role\": \"user\", \"content\": \"Which one is bigger between 9.9 and 9.11\"}],\n","    temperature=0.5,\n","    top_p=1,\n","    max_tokens=1024,\n","    stream=False\n",")\n","\n","# Access the response content directly\n","print(completion.choices[0].message.content)\n"]},{"cell_type":"markdown","source":["### Stream the Output"],"metadata":{"id":"X2llvhdnwYK9"}},{"cell_type":"code","source":["completion = client.chat.completions.create(\n","    model=\"meta/llama-3.2-3b-instruct\",\n","    messages=[\n","        {\"role\": \"user\", \"content\": \"What is the latest GPU model from NVIDIA\"}\n","    ],\n","    temperature=0.5,\n","    top_p=1,\n","    max_tokens=1024,\n","    stream=True\n",")\n","\n","for chunk in completion:\n","    if chunk.choices[0].delta.content is not None:\n","        print(chunk.choices[0].delta.content, end=\"\")\n"],"metadata":{"id":"xrjEyW9LwYdA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Call Embedding model"],"metadata":{"id":"HFoNThnR4HVq"}},{"cell_type":"code","source":["from openai import OpenAI\n","\n","response = client.embeddings.create(\n","    input=[\"What is the capital of France?\"],\n","    model=\"nvidia/llama-3.2-nv-embedqa-1b-v2\",\n","    encoding_format=\"float\",\n","    extra_body={\"input_type\": \"query\", \"truncate\": \"NONE\"}\n",")\n","\n","print(response.data[0].embedding)\n"],"metadata":{"id":"xWfIqn5I4ED7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Wle4bGql4M9a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Alternative #2:  Call NIM using Python's requests library"],"metadata":{"id":"mBPL-of4cGBa"}},{"cell_type":"code","source":["import requests\n","import json\n","import os\n","\n","from google.colab import userdata\n","os.environ['NVIDIA_API_KEY'] = userdata.get('NVIDIA_API_KEY')\n","apikey = os.getenv('NVIDIA_API_KEY')\n","\n","def MyChat(prompt: str, max_tokens: int = 150, temperature: float = 0.7):\n","    \"\"\"\n","    Send a prompt to the Llama-3.2-3B-Instruct model via NIM API.\n","    \"\"\"\n","    url = \"https://integrate.api.nvidia.com/v1/chat/completions\"\n","    headers = {\n","        \"Content-Type\": \"application/json\",\n","        \"Authorization\": f\"Bearer {apikey}\" # Add the API key here\n","    }\n","    data = {\n","        \"model\": \"meta/llama-3.2-3b-instruct\",\n","        \"messages\": [\n","            {\"role\": \"user\", \"content\": prompt}\n","        ],\n","        \"max_tokens\": max_tokens,\n","        \"temperature\": temperature,\n","        \"stream\": False\n","    }\n","\n","    response = requests.post(url, headers=headers, data=json.dumps(data))\n","\n","    if response.status_code == 200:\n","        result = response.json()\n","        return result['choices'][0]['message']['content']\n","    else:\n","        raise Exception(f\"Error {response.status_code}: {response.text}\")\n","\n","# Example Usage\n","prompt = \"Explain the concept of gravity in simple terms.\"\n","response = MyChat(prompt)\n","print(\"ü§ñ Response:\", response)"],"metadata":{"id":"s8DAKc7VcFW8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### üìù Step 3: Try It Yourself\n","\n","**Exercise**: Modify the prompt above to ask the model to explain what an LLM is in one sentence."],"metadata":{"id":"EeN-1zSNTbP5"}},{"cell_type":"code","source":[],"metadata":{"id":"4oXF6qSkdqIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Be3jcIatT1Tr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XkTWUCDIcQtF"},"execution_count":null,"outputs":[]}]}